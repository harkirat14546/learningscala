mediafirst {

  input.logs.filter.group           = "7" //RCS.jobs.serviceRealtimeReports.input.logs.filter.group
  input.logs.format                 = "Kafka"
  //input.logs.adapter                = Kafka
  input.logs.topic                   = "elasticsearchtopicperfs"
   input.logs.offsetStoreAdapter      = none
  input.logs.groupId                 = "goli"
  input.logs.brokersConnectionString = "localhost:9092" //RCS.KafkaClusterServers

  input.sts.authfailures.filter = "sts,operatorsts"
  input.oss.proxyerrors.filter = "oss"

  output.logs.stsperformance.topic = "anlx-realtimefeedstsperformancemetrics-test" //RCS.jobs.serviceRealtimeReports.output.logs.stsperformance.topic
  output.logs.ossproxyapiperformance.topic = "anlx-realtimefeedossproxyapiperformancemetrics-test" //RCS.jobs.serviceRealtimeReports.output.logs.ossproxyapiperformance.topic
  output.logs.serviceapiperformance.topic = "anlx-realtimefeedserviceapiperformancemetrics-test1" //RCS.jobs.serviceRealtimeReports.output.logs.serviceapiperformance.topic
  output.checkpointdirectory= "/home/azure"  //RCS.jobs.serviceRealtimeReports.output.checkpointdirectory

  // Spark
  spark.masterUrl              = "local[*]" //RCS._
  spark.driver.memory          = RCS.jobs.serviceRealtimeReports.run.spark.driver.memory
  spark.executor.memory        = RCS.jobs.serviceRealtimeReports.run.spark.executor.memory
  spark.cores.max              = "2" // RCS.jobs.serviceRealtimeReports.scheduling.initialCores
  spark.ui.port                = RCS.jobs.serviceRealtimeReports.run.spark.ui.port
  spark.streaming.kafka.consumer.cache.enabled = false

  // Environment information
  site            : RCS._
  operator        : RCS._
  environment     : RCS._
  fullEnvironment : RCS._

  // sts token
  sts.keyStoreFilePath = RCS._
  sts.keyStorePassword = RCS._
  sts.tokenProviderUri = RCS._

  // Instrumentation
  sparkInstrumentation {
    sink.local.enable         : RCS.jobs.serviceRealtimeReports.instrumentation.sink.local.enabled
    sink.elasticsearch.enable : RCS.jobs.serviceRealtimeReports.instrumentation.sink.elastic.enabled
    sink.elasticsearch.index  : RCS.instrumentation.sink.elasticsearch.index
  }

  // Logging
  sparkLogger {
    sink.local.enable         : RCS.jobs.serviceRealtimeReports.logging.sink.local.enabled
    sink.local.level          : RCS.jobs.serviceRealtimeReports.logging.sink.local.level
    sink.elasticsearch.enable : RCS.jobs.serviceRealtimeReports.logging.sink.elastic.enabled
    sink.elasticsearch.level  : RCS.jobs.serviceRealtimeReports.logging.sink.elastic.level
    sink.kafka.enable         = RCS.jobs.serviceRealtimeReports.logging.sink.kafka.enabled
    sink.kafka.level          = RCS.jobs.serviceRealtimeReports.logging.sink.kafka.level
    sink.elasticsearch.index  : RCS.log.sink.elasticsearch.index
  }

  // Elasticsearch configuration
  es.data.host                : RCS._  //"esmfdata.dev.mr.tv3cloud.com"
  es.data.clusterName         : RCS._  //"tv3mfescluster"
  es.data.nativePort          : RCS._
  es.data.transportClientPort : RCS._
  es.data.username            : RCS._  //"temp_user"
  es.data.password            : RCS._  //"tempEla5tic"
  es.data.ssl                 : RCS._

  // Kafka
  kafka.analytics.brokersConnectionString = RCS.KafkaClusterServers
  kafka.analytics.debug = false

  //sparkInstrumentation.sink.elasticsearch.index = "spark-app-instrumentation"

  streamingDuration: 60 //in seconds.
  streaming.windowSize: 600 //in seconds.
  streaming.slideSize: 120 //in seconds.


  report.prefix: RCS.jobs.serviceRealtimeReports.report.prefix //"realtimefeed"
  instrumentation.event.name: "realtimereports://service (K)"
//  processing.initStartTime: "2016-06-11T10:08:59.999Z"
//  processing.initEndTime: "2016-06-11T10:18:00.000Z"

   startTimeBatch: "1 days ago"
  startTimeMode : "latest" // could be "latest" or "defined"
  endTimeBatch  : "01/06/2015 23:59:59"
  endTimeMode   : "duration" // could be "latest" or "duration" or "now"
  duration      : "2" // in minutes
  latency       : "2" // in minutes
  autoIncrease  : "on"
  timeRangeMode : "range"
  performCount  : "false"
  wait          : "1" // in seconds
}